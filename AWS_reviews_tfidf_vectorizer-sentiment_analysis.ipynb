{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7018f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24057f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 13)\n",
      "   Unnamed: 0  overall  verified   reviewTime      reviewerID        asin  \\\n",
      "0           0      4.0      True  03 11, 2014  A240ORQ2LF9LUI  0077613252   \n",
      "1           1      4.0      True  02 23, 2014  A1YCCU0YRLS0FE  0077613252   \n",
      "2           2      1.0      True  02 17, 2014  A1BJHRQDYVAY2J  0077613252   \n",
      "3           3      3.0      True  02 17, 2014   APRDVZ6QBIQXT  0077613252   \n",
      "4           4      5.0     False  10 14, 2013  A2JZTTBSLS1QXV  0077775473   \n",
      "\n",
      "                        style         reviewerName  \\\n",
      "0  {'Format:': ' Loose Leaf'}           Michelle W   \n",
      "1  {'Format:': ' Loose Leaf'}  Rosalind White Ames   \n",
      "2  {'Format:': ' Loose Leaf'}       Allan R. Baker   \n",
      "3  {'Format:': ' Loose Leaf'}                 Lucy   \n",
      "4                         NaN            Albert V.   \n",
      "\n",
      "                                          reviewText  \\\n",
      "0  The materials arrived early and were in excell...   \n",
      "1  I am really enjoying this book with the worksh...   \n",
      "2  IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR ...   \n",
      "3  This book was missing pages!!! Important pages...   \n",
      "4  I have used LearnSmart and can officially say ...   \n",
      "\n",
      "                         summary  unixReviewTime vote image  \n",
      "0                 Material Great      1394496000  NaN   NaN  \n",
      "1                         Health      1393113600  NaN   NaN  \n",
      "2             ARE YOU KIDING ME?      1392595200    7   NaN  \n",
      "3                missing pages!!      1392595200    3   NaN  \n",
      "4  Best study product out there!      1381708800  NaN   NaN  \n"
     ]
    }
   ],
   "source": [
    "# Define the path to your CSV file and the chunk size\n",
    "file_path = \"C:/Users/HP/OneDrive/Desktop/Internship/xlsheets/aws_review_sofware_dataset.csv\"\n",
    "chunk_size = 25000\n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "data = pd.DataFrame()\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "    data = pd.concat([data, chunk], ignore_index=True)\n",
    "    if len(data)>=25000: # Indentation fixed here\n",
    "        data=data.iloc[:25000]\n",
    "        break # Indentation fixed here; break should occur within the if block\n",
    "\n",
    "# Now `data` contains the entire DataFrame\n",
    "print(data.shape) \n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe69f5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "      <th>words</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 11, 2014</td>\n",
       "      <td>A240ORQ2LF9LUI</td>\n",
       "      <td>0077613252</td>\n",
       "      <td>{'Format:': ' Loose Leaf'}</td>\n",
       "      <td>Michelle W</td>\n",
       "      <td>The materials arrived early and were in excell...</td>\n",
       "      <td>Material Great</td>\n",
       "      <td>1394496000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[the, material, arrive, early, and, be, in, ex...</td>\n",
       "      <td>[The materials arrived early and were in excel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 23, 2014</td>\n",
       "      <td>A1YCCU0YRLS0FE</td>\n",
       "      <td>0077613252</td>\n",
       "      <td>{'Format:': ' Loose Leaf'}</td>\n",
       "      <td>Rosalind White Ames</td>\n",
       "      <td>I am really enjoying this book with the worksh...</td>\n",
       "      <td>Health</td>\n",
       "      <td>1393113600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[i, be, really, enjoy, this, book, with, the, ...</td>\n",
       "      <td>[I am really enjoying this book with the works...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 17, 2014</td>\n",
       "      <td>A1BJHRQDYVAY2J</td>\n",
       "      <td>0077613252</td>\n",
       "      <td>{'Format:': ' Loose Leaf'}</td>\n",
       "      <td>Allan R. Baker</td>\n",
       "      <td>IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR ...</td>\n",
       "      <td>ARE YOU KIDING ME?</td>\n",
       "      <td>1392595200</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[if, you, be, take, this, class, don, '', t, w...</td>\n",
       "      <td>[IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 17, 2014</td>\n",
       "      <td>APRDVZ6QBIQXT</td>\n",
       "      <td>0077613252</td>\n",
       "      <td>{'Format:': ' Loose Leaf'}</td>\n",
       "      <td>Lucy</td>\n",
       "      <td>This book was missing pages!!! Important pages...</td>\n",
       "      <td>missing pages!!</td>\n",
       "      <td>1392595200</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[this, book, be, miss, page, !, !, !, importan...</td>\n",
       "      <td>[This book was missing pages!!!, Important pag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10 14, 2013</td>\n",
       "      <td>A2JZTTBSLS1QXV</td>\n",
       "      <td>0077775473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albert V.</td>\n",
       "      <td>I have used LearnSmart and can officially say ...</td>\n",
       "      <td>Best study product out there!</td>\n",
       "      <td>1381708800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[i, have, use, learnsmart, and, can, officiall...</td>\n",
       "      <td>[I have used LearnSmart and can officially say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0           0      4.0      True  03 11, 2014  A240ORQ2LF9LUI  0077613252   \n",
       "1           1      4.0      True  02 23, 2014  A1YCCU0YRLS0FE  0077613252   \n",
       "2           2      1.0      True  02 17, 2014  A1BJHRQDYVAY2J  0077613252   \n",
       "3           3      3.0      True  02 17, 2014   APRDVZ6QBIQXT  0077613252   \n",
       "4           4      5.0     False  10 14, 2013  A2JZTTBSLS1QXV  0077775473   \n",
       "\n",
       "                        style         reviewerName  \\\n",
       "0  {'Format:': ' Loose Leaf'}           Michelle W   \n",
       "1  {'Format:': ' Loose Leaf'}  Rosalind White Ames   \n",
       "2  {'Format:': ' Loose Leaf'}       Allan R. Baker   \n",
       "3  {'Format:': ' Loose Leaf'}                 Lucy   \n",
       "4                         NaN            Albert V.   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  The materials arrived early and were in excell...   \n",
       "1  I am really enjoying this book with the worksh...   \n",
       "2  IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR ...   \n",
       "3  This book was missing pages!!! Important pages...   \n",
       "4  I have used LearnSmart and can officially say ...   \n",
       "\n",
       "                         summary  unixReviewTime vote image  \\\n",
       "0                 Material Great      1394496000  NaN   NaN   \n",
       "1                         Health      1393113600  NaN   NaN   \n",
       "2             ARE YOU KIDING ME?      1392595200    7   NaN   \n",
       "3                missing pages!!      1392595200    3   NaN   \n",
       "4  Best study product out there!      1381708800  NaN   NaN   \n",
       "\n",
       "                                               words  \\\n",
       "0  [the, material, arrive, early, and, be, in, ex...   \n",
       "1  [i, be, really, enjoy, this, book, with, the, ...   \n",
       "2  [if, you, be, take, this, class, don, '', t, w...   \n",
       "3  [this, book, be, miss, page, !, !, !, importan...   \n",
       "4  [i, have, use, learnsmart, and, can, officiall...   \n",
       "\n",
       "                                           sentences  \n",
       "0  [The materials arrived early and were in excel...  \n",
       "1  [I am really enjoying this book with the works...  \n",
       "2  [IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR...  \n",
       "3  [This book was missing pages!!!, Important pag...  \n",
       "4  [I have used LearnSmart and can officially say...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c65b2286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'overall', 'verified', 'reviewTime', 'reviewerID', 'asin',\n",
       "       'style', 'reviewerName', 'reviewText', 'summary', 'unixReviewTime',\n",
       "       'vote', 'image'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e77c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"words\"]=\"default value\"\n",
    "data[\"sentences\"]=\"default value\"\n",
    "\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    data.at[i,\"words\"]= list(\"\")\n",
    "    data.at[i,\"sentences\"] = list(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c2c4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3535a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(499):\n",
    "    l1= sent_tokenize(data.loc[i,\"reviewText\"])\n",
    "    data.at[i,\"sentences\"]=l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6157101",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pywsd -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a60004a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... took 7.936540126800537 secs.\n"
     ]
    }
   ],
   "source": [
    "from pywsd.utils import lemmatize_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c76f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fce280a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(data.shape[0]):\n",
    "    data.at[k,\"words\"]=list(\"\")\n",
    "    for j in range(len(data.loc[k,\"sentences\"])):\n",
    "        data.at[k,\"words\"].extend(lemmatize_sentence(data.loc[k,\"sentences\"][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4176781",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"words_sentences\"] = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "125ee6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "for k in range(data.shape[0]):\n",
    "    words_list = data.loc[k, \"words\"]\n",
    "    \n",
    "    if words_list:  # Check if the list is not empty\n",
    "        data.loc[k, \"words_sentences\"] = functools.reduce(lambda a, b: str(a) + \" \" + str(b), words_list)\n",
    "    else:\n",
    "        data.loc[k, \"words_sentences\"] = \"\"  # Assign an empty string if the list is empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6aff379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30c02425",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data.words_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44981737",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x= pd.DataFrame(tfidf_matrix.todense(), columns=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5957ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y=data[\"verified\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb652aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89700b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e815476",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y=pd.DataFrame(L_encoder.fit_transform(data_y),columns=[\"verified\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f228f07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   verified\n",
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d64b23",
   "metadata": {},
   "source": [
    "## TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d05b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e32646",
   "metadata": {},
   "source": [
    "## GRADIENT BOOSTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "736fbbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score : 70.86857142857143\n",
      "accuracy_score :  70.36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBR = GradientBoostingClassifier(random_state=42)\n",
    "GBR.fit(x_train, y_train)\n",
    "y_pred=GBR.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "training_score = GBR.score(x_train, y_train)*100\n",
    "print(f'Training Score : {training_score}')\n",
    "print(\"accuracy_score : \",accuracy_score(y_test,y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef75ce8",
   "metadata": {},
   "source": [
    "## RANDOMFOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4dac3217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score : 70.90857142857143\n",
      "accuracy_score :  70.52000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(random_state=42)\n",
    "RF.fit(x_train, y_train)\n",
    "y_pred=RF.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "training_score = RF.score(x_train, y_train)*100\n",
    "print(f'Training Score : {training_score}')\n",
    "print(\"accuracy_score : \",accuracy_score(y_test,y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824dd861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
